{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OctoAI SDXL on SageMaker through Model Packages\n",
    "\n",
    "OctoAI SDXL is a performant and feature-rich SDXL implementation, allowing users to easily generate images, modify existing images using image-to-image, as well as a host of other capabilities. You can read more about what's possible in the [documentation](https://octo.ai/docs/octostack/sagemaker)\n",
    "\n",
    "This sample notebook shows you how to deploy OctoAI SDXL using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
    "\n",
    "## Contents:\n",
    "1. [Select model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select to the model package\n",
    "Confirm that you recieved this notebook from model catalog on SageMaker AWS Management Console.\n",
    "\n",
    "Note that you will have to subscribe to the OctoAI SDXL product on the AWS Marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)\n",
    "model_package_map = {\n",
    "    \"us-east-1\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"us-west-1\": \"arn:aws:sagemaker:us-west-1:382657785993:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"us-west-2\": \"arn:aws:sagemaker:us-west-2:594846645681:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ca-central-1\": \"arn:aws:sagemaker:ca-central-1:470592106596:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"eu-central-1\": \"arn:aws:sagemaker:eu-central-1:446921602837:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"eu-west-1\": \"arn:aws:sagemaker:eu-west-1:985815980388:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"eu-west-2\": \"arn:aws:sagemaker:eu-west-2:856760150666:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"eu-west-3\": \"arn:aws:sagemaker:eu-west-3:843114510376:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"eu-north-1\": \"arn:aws:sagemaker:eu-north-1:136758871317:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ap-southeast-1\": \"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ap-southeast-2\": \"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ap-northeast-2\": \"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ap-northeast-1\": \"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"ap-south-1\": \"arn:aws:sagemaker:ap-south-1:077584701553:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "    \"sa-east-1\": \"arn:aws:sagemaker:sa-east-1:270155090741:model-package/octoai-sdxl-f213d1052497ffea6b-5237376082f63d8a848ceecdf1393e1f\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sagemaker_session = sage.Session(boto_session=boto_session)\n",
    "role = get_execution_role(sagemaker_session=sagemaker_session)\n",
    "\n",
    "runtime_sm_client = boto_session.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can change this to whatever you'd like to name your SDXL endpoint\n",
    "model_name = \"sdxl\"\n",
    "\n",
    "initial_instance_count = 1\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.g5.4xlarge\"\n",
    "    # other possible options are:\n",
    "    # ml.g5.xlarge  \n",
    "    # ml.g5.2xlarge \n",
    "    # ml.g5.4xlarge \n",
    "    # ml.g5.8xlarge \n",
    "    # ml.g5.12xlarge\n",
    "    # ml.g5.16xlarge\n",
    "    # ml.g5.24xlarge\n",
    "    # ml.g5.48xlarge\n",
    "    # ml.p4d.24xlarge\n",
    "    # ml.p4de.24xlarge\n",
    "    # ml.p5.48xlarge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(initial_instance_count, real_time_inference_instance_type, endpoint_name=model_name, model_data_download_timeout=1200, container_startup_health_check_timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you can use it to generate images, where you can see examples in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the SDXL API to generate a variety of images, including doing text-to-image, image-to-image, inpainting, outpainting and PhotoMerge. You can look to the [documentation](https://octo.ai/docs/octostack/sagemaker) to see a complete description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple text-to-image payload, generating a single image\n",
    "payload = {\n",
    "    \"prompt\": \"A wizard octopus in the forest conjuring a spell\",\n",
    "    \"negative_prompt\": \"Blurry,low-res,poor quality\",\n",
    "    \"steps\": 30,\n",
    "    \"num_images\": 1,\n",
    "    \"sampler\": \"DDIM\",\n",
    "    \"cfg_scale\": 12,\n",
    "    \"width\": 1024,\n",
    "    \"height\": 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Add code snippet that shows the payload contents>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    ContentType=content_type,\n",
    "    Body=json.dumps(payload),\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OctoAI SDXL will return a JSON payload that includes all the images generated, each encoded in base64. The structure looks like this:\n",
    "\n",
    "```\n",
    "    {\n",
    "        \"images\": [\n",
    "            {\n",
    "                \"image_b64\":\"<base64 encoded image>\",\n",
    "                \"removed_for_safety\":<true|false>,\n",
    "                \"seed\":<integer>\n",
    "            },\n",
    "            { ... }\n",
    "        ]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a simple helper function that will take the output and display all the generated images (in the case where more than a single image was returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from base64 import b64decode\n",
    "\n",
    "def display_output(endpoint_output):\n",
    "    # Convert each base64-encoded image and display all of them\n",
    "    imgs = []\n",
    "    for output_img in endpoint_output[\"images\"]:\n",
    "        decoded_image = b64decode(output_img[\"image_b64\"])\n",
    "        imgs.append(display.Image(decoded_image))\n",
    "    display.display(*imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use it on the output we previously received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to SDXL, your endpoint also supports SDXL Lightning, allowing you to create high-quality images faster, by utilizing a shorter number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_payload = {\n",
    "    \"prompt\": \"A wizard octopus in the forest conjuring a spell\",\n",
    "    \"negative_prompt\": \"Blurry,low-res,poor quality\",\n",
    "    \"num_images\": 1,\n",
    "    \"sampler\": \"DDIM\",\n",
    "    \"width\": 1024,\n",
    "    \"height\": 1024,\n",
    "\n",
    "    # The main changes are:\n",
    "    # 1. A lower number of steps\n",
    "    # 2. A lower CFG scale\n",
    "    # 3. Specifying the SDXL Lightning checkpoint\n",
    "    # You can still change other parameters, such as number of images, resolution, sampler, etc\n",
    "    \"steps\": 8,\n",
    "    \"cfg_scale\": 2,\n",
    "    \"checkpoint\": \"octoai:lightning_sdxl\"\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    ContentType=content_type,\n",
    "    Body=json.dumps(lightning_payload),\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "display_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to generating images from text, we can also generate images from other images, utilizing the same performance and functionality (this also works with SDXL Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from base64 import b64encode, b64decode\n",
    "\n",
    "# Read the image and encode it as base64\n",
    "init_image = b64encode(open('./astronaut.png', 'rb').read()).decode(\"utf-8\")\n",
    "\n",
    "img2img_payload = {\n",
    "    \"prompt\": \"breathtaking, american woman, award winning photography, best quality, 8K HDR\",\n",
    "    \"negative_prompt\": \"worst quality, low quality, bad quality, lazy eye\",\n",
    "    \"width\": 1344,\n",
    "    \"height\": 768,\n",
    "    \"num_images\": 1,\n",
    "    \"sampler\": \"DDIM\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 12,\n",
    "    \"use_refiner\": False,\n",
    "    \"style_preset\": \"neon-punk\",\n",
    "    \"strength\": 0.8,\n",
    "    \"init_image\": init_image,\n",
    "\n",
    "    # We use a specific seed to get a specific image out, but you can\n",
    "    # change this or omit it\n",
    "    \"seed\": 2701628909,\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    ContentType=content_type,\n",
    "    Body=json.dumps(img2img_payload),\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "print(\"Generated image\")\n",
    "display_output(output)\n",
    "\n",
    "# display original image too for comparison\n",
    "print(\"Original image\")\n",
    "display.Image(b64decode(init_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
